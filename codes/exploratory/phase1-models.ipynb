{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Model Testing\n",
    "## Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fund_symbol', 'price_year', 'avg_open', 'avg_high', 'avg_low',\n",
      "       'avg_close', 'avg_adj_close', 'avg_transaction_price',\n",
      "       'avg_transaction_volume', 'avg_transaction_value', 'yearly_risk',\n",
      "       'yearly_loss'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fund_symbol</th>\n",
       "      <th>price_year</th>\n",
       "      <th>avg_open</th>\n",
       "      <th>avg_high</th>\n",
       "      <th>avg_low</th>\n",
       "      <th>avg_close</th>\n",
       "      <th>avg_adj_close</th>\n",
       "      <th>avg_transaction_price</th>\n",
       "      <th>avg_transaction_volume</th>\n",
       "      <th>avg_transaction_value</th>\n",
       "      <th>yearly_risk</th>\n",
       "      <th>yearly_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2020</td>\n",
       "      <td>24.989500</td>\n",
       "      <td>24.996000</td>\n",
       "      <td>24.985000</td>\n",
       "      <td>24.988750</td>\n",
       "      <td>24.799375</td>\n",
       "      <td>24.799375</td>\n",
       "      <td>6360.000000</td>\n",
       "      <td>1.575589e+05</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>-0.002405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.182737</td>\n",
       "      <td>12.229579</td>\n",
       "      <td>12.148947</td>\n",
       "      <td>12.171579</td>\n",
       "      <td>12.171579</td>\n",
       "      <td>12.171579</td>\n",
       "      <td>103495.789474</td>\n",
       "      <td>1.252533e+06</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>-0.012490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>2019</td>\n",
       "      <td>13.921230</td>\n",
       "      <td>13.968056</td>\n",
       "      <td>13.873294</td>\n",
       "      <td>13.920317</td>\n",
       "      <td>13.920317</td>\n",
       "      <td>13.920317</td>\n",
       "      <td>57093.650794</td>\n",
       "      <td>8.173461e+05</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>-0.023196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>2020</td>\n",
       "      <td>17.696047</td>\n",
       "      <td>17.776917</td>\n",
       "      <td>17.577036</td>\n",
       "      <td>17.681818</td>\n",
       "      <td>17.681818</td>\n",
       "      <td>17.681818</td>\n",
       "      <td>411806.719368</td>\n",
       "      <td>7.529092e+06</td>\n",
       "      <td>0.012494</td>\n",
       "      <td>-0.054978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AADR</td>\n",
       "      <td>2010</td>\n",
       "      <td>27.727478</td>\n",
       "      <td>27.799913</td>\n",
       "      <td>27.633565</td>\n",
       "      <td>27.734522</td>\n",
       "      <td>26.044261</td>\n",
       "      <td>26.044261</td>\n",
       "      <td>5478.260870</td>\n",
       "      <td>1.424816e+05</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>-0.034893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fund_symbol  price_year   avg_open   avg_high    avg_low  avg_close  \\\n",
       "0         AAA        2020  24.989500  24.996000  24.985000  24.988750   \n",
       "1        AAAU        2018  12.182737  12.229579  12.148947  12.171579   \n",
       "2        AAAU        2019  13.921230  13.968056  13.873294  13.920317   \n",
       "3        AAAU        2020  17.696047  17.776917  17.577036  17.681818   \n",
       "4        AADR        2010  27.727478  27.799913  27.633565  27.734522   \n",
       "\n",
       "   avg_adj_close  avg_transaction_price  avg_transaction_volume  \\\n",
       "0      24.799375              24.799375             6360.000000   \n",
       "1      12.171579              12.171579           103495.789474   \n",
       "2      13.920317              13.920317            57093.650794   \n",
       "3      17.681818              17.681818           411806.719368   \n",
       "4      26.044261              26.044261             5478.260870   \n",
       "\n",
       "   avg_transaction_value  yearly_risk  yearly_loss  \n",
       "0           1.575589e+05     0.000700    -0.002405  \n",
       "1           1.252533e+06     0.006177    -0.012490  \n",
       "2           8.173461e+05     0.007424    -0.023196  \n",
       "3           7.529092e+06     0.012494    -0.054978  \n",
       "4           1.424816e+05     0.009560    -0.034893  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/cleaned-yearly-ETFs.csv')\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['price_year'] == 2018) | (df['price_year'] == 2019) | (df['price_year'] == 2020)]\n",
    "df['yearly_risk'].describe(percentiles=[0.25, 0.5, 0.75])\n",
    "df['yearly_risk'] = (df['yearly_risk'] > 0.10619).astype(int)\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop(columns=['fund_symbol','price_year', 'yearly_risk']).to_numpy(dtype=np.float32)\n",
    "y = df['yearly_risk'].to_numpy(dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Preferential Attachment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erinb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\erinb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9972875226039783\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1103\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           1.00      1106\n",
      "   macro avg       0.50      0.50      0.50      1106\n",
      "weighted avg       0.99      1.00      1.00      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erinb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\erinb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\erinb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model_PA.joblib']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a directed graph for preferential attachment\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# initialize graph\n",
    "for i in range(5):\n",
    "    G.add_node(i)\n",
    "\n",
    "# add edges with prefferential attachment method \n",
    "for new_node in range(5, len(df)):\n",
    "    degrees = np.array([G.degree(n) for n in G.nodes()])\n",
    "    if degrees.sum() > 0:\n",
    "        probabilities = degrees / degrees.sum()\n",
    "    #assume unif if small\n",
    "    else:\n",
    "        probabilities = np.ones(len(G.nodes())) / len(G.nodes())\n",
    "    target_node = np.random.choice(G.nodes(), p=probabilities)\n",
    "    G.add_edge(new_node, target_node)\n",
    "\n",
    "# get node features and add to df\n",
    "degree_features = np.array([G.degree(i) for i in range(len(X))]).reshape(-1, 1)\n",
    "neighbor_degree_features = np.array([np.mean([G.degree(n) for n in G.neighbors(i)]) for i in range(len(X))]).reshape(-1, 1)\n",
    "X_combined = np.hstack((X, degree_features, neighbor_degree_features))\n",
    "mask = ~np.isnan(X_combined).any(axis=1)\n",
    "X_combined = X_combined[mask]\n",
    "y_pa = y[mask]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_pa, test_size=0.2, random_state=42)\n",
    "\n",
    "# classify with k-nearest neighbors\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit model with training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#save model\n",
    "joblib.dump(model, './model_PA.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erinb\\AppData\\Local\\Temp\\ipykernel_12604\\3679770458.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n",
      "C:\\Users\\erinb\\AppData\\Local\\Temp\\ipykernel_12604\\3679770458.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.int64)  # Ensure y is int for classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9981949458483754\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1106\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00      1108\n",
      "   macro avg       0.50      0.50      0.50      1108\n",
      "weighted avg       1.00      1.00      1.00      1108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erinb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\erinb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\erinb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_nn.joblib']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data to tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.int64)  \n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "# Get device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# Define NN class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Instantiate model\n",
    "input_size = X_train.shape[1]\n",
    "model = NeuralNetwork(input_size).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test = X_test.to(device)\n",
    "    y_pred_logits = model(X_test)\n",
    "    y_pred = torch.argmax(y_pred_logits, dim=1).cpu().numpy() \n",
    "\n",
    "# classification metrics\n",
    "accuracy = accuracy_score(y_test.cpu().numpy(), y_pred)\n",
    "report = classification_report(y_test.cpu().numpy(), y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "#save model\n",
    "joblib.dump(model, './model_nn.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models performed with extremely high accuracy. The PA model performed at 99.7% accuracy, whereas the neural network performed at 99.8% accuracy. It should be noted that the PA model required some input firms to be dropped (9). It should also be noted that the neural network requires higher computational power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
