{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase II: Simulation\n",
    "## Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/cleaned-yearly-ETFs.csv')\n",
    "\n",
    "df = df[(df['price_year'] == 2018) | (df['price_year'] == 2019) | (df['price_year'] == 2020)]\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop(columns=['fund_symbol','price_year', 'yearly_risk']).to_numpy(dtype=np.float32)\n",
    "y = df['yearly_risk'].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NN class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model_pa = joblib.load('model_PA.joblib')\n",
    "model_nn = joblib.load('model_nn.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sim_open   sim_high    sim_low  sim_close  sim_adj_close  sim_price  \\\n",
      "0   47.298814  33.046853  86.463636  23.975929     143.891621  24.389717   \n",
      "1   28.624071  37.937928  19.300556  26.691779      27.052063  96.660876   \n",
      "2  113.173597  79.923434  46.271587  19.342500      31.705777  42.260558   \n",
      "3   80.071507  31.383730  24.257895  99.273586      38.576151  54.774743   \n",
      "4   29.232669  33.408458  57.582032  24.998214      63.686786  30.592351   \n",
      "\n",
      "         sim_vol     sim_value  sim_loss  \n",
      "0    2229.365079  4.021210e+06 -0.241921  \n",
      "1    2890.000000  1.047132e+06 -0.075510  \n",
      "2    9710.714286  4.582998e+05 -0.032150  \n",
      "3  603821.115538  6.995109e+04 -0.109756  \n",
      "4   48067.984190  1.469424e+06 -0.168219  \n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "# random average transaction generation\n",
    "np.random.seed(42)\n",
    "sim_open = df['avg_open'].sample(n, replace=True).values \n",
    "sim_high = df['avg_high'].sample(n, replace=True).values \n",
    "sim_low = df['avg_low'].sample(n, replace=True).values \n",
    "sim_close = df['avg_close'].sample(n, replace=True).values \n",
    "sim_adj_close = df['avg_adj_close'].sample(n, replace=True).values \n",
    "sim_price = df['avg_transaction_price'].sample(n, replace=True).values \n",
    "sim_vol = df['avg_transaction_volume'].sample(n, replace=True).values \n",
    "sim_value = df['avg_transaction_value'].sample(n, replace=True).values \n",
    "sim_loss = df['yearly_loss'].sample(n, replace=True).values \n",
    "\n",
    "# Simulation DataFrame\n",
    "simulation = pd.DataFrame({\n",
    "    'sim_open': sim_open,\n",
    "    'sim_high': sim_high,\n",
    "    'sim_low': sim_low,\n",
    "    'sim_close': sim_close,\n",
    "    'sim_adj_close': sim_adj_close,\n",
    "    'sim_price': sim_price,\n",
    "    'sim_vol': sim_vol,\n",
    "    'sim_value': sim_value,\n",
    "    'sim_loss': sim_loss\n",
    "})\n",
    "\n",
    "print(simulation.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value-at-Risk Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get returns\n",
    "simulation['returns'] = simulation['sim_open'] - simulation['sim_close']\n",
    "conf = 0.95\n",
    "\n",
    "# VaR for each row\n",
    "simulation['var'] = simulation['returns'].apply(lambda x: np.percentile(simulation['returns'], (1 - conf) * 100))\n",
    "\n",
    "# Calculate simulation VaR for each row\n",
    "simulation['simulated_VaR'] = simulation['var'] * simulation['sim_value']\n",
    "\n",
    "# Get the median VaR\n",
    "median_var = simulation['var'].median()\n",
    "\n",
    "# Classify as high or low risk based on median VaR\n",
    "simulation['risk_sim'] = simulation['var'].apply(lambda x: 1 if x > median_var else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preferential Attachment Model Risk Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erinb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "simulation = simulation.dropna()\n",
    "simulation = simulation.drop(columns=['var', 'returns'])\n",
    "predictions = model_pa.predict(simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = simulation['risk_sim'].values == predictions\n",
    "\n",
    "sum(comparison == True)/len(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prefferential attachment model was completely concordand with Value at Risk (VaR) predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model Risk Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.eval()\n",
    "input_data = torch.tensor(simulation[['sim_open', 'sim_high', 'sim_low', 'sim_close', 'sim_adj_close', 'sim_price', 'sim_vol', 'sim_value', 'sim_loss']].values, dtype=torch.float32)\n",
    "\n",
    "#forward pass\n",
    "with torch.no_grad(): \n",
    "    outputs = model_nn(input_data)\n",
    "\n",
    "\n",
    "predictions = torch.sigmoid(outputs)\n",
    "pred = (predictions > 0.5).int()\n",
    "\n",
    "simulation['prediction_nn'] = pred[:, 0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = simulation['risk_sim'].values == simulation['prediction_nn'].values\n",
    "\n",
    "sum(comparison == True)/len(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prefferential attachment model was completely concordand with Value at Risk (VaR) predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simualtion, both the neural network model and the prefferential attachment model performed in accordance with the gold standard for risk calculation in finance, Value at Risk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
